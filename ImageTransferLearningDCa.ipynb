{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from bigdl.util.common import *\n",
    "from bigdl.transform.vision.image import *\n",
    "from bigdl.transform.vision import image\n",
    "from pyspark.sql.functions import col, udf\n",
    "from pyspark.sql.types import DoubleType, StringType\n",
    "from bigdl.nn.layer import *\n",
    "from bigdl.nn.criterion import *\n",
    "from pyspark import SparkConf\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "from zoo.common.nncontext import *\n",
    "from zoo.pipeline.nnframes.nn_classifier import *\n",
    "from zoo.pipeline.nnframes.nn_image_reader import *\n",
    "from zoo.pipeline.nnframes.nn_image_transformer import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Partition number: ', 12)\n",
      "('Image number', 2222)\n",
      "creating: createResize\n",
      "creating: createCenterCrop\n",
      "creating: createChannelNormalize\n",
      "creating: createPipeline\n",
      "creating: createNNImageTransformer\n",
      "creating: createNNModel\n",
      "Loaded pretrained model\n",
      "creating: createSequential\n",
      "creating: createLinear\n",
      "creating: createLogSoftMax\n",
      "creating: createClassNLLCriterion\n",
      "creating: createNNClassifier\n",
      "stage 1\n",
      "start training\n",
      "end training\n",
      "+--------------------+------------+-----+--------------------+--------------------+----------+\n",
      "|               image|        name|label|            features|           embedding|prediction|\n",
      "+--------------------+------------+-----+--------------------+--------------------+----------+\n",
      "|[file:/Users/sver...|cat.5116.jpg|  1.0|[file:/Users/sver...|[2.18015699715579...|       1.0|\n",
      "|[file:/Users/sver...|cat.5170.jpg|  1.0|[file:/Users/sver...|[5.75808542180311...|       2.0|\n",
      "|[file:/Users/sver...| cat.529.jpg|  1.0|[file:/Users/sver...|[3.48281209880951...|       2.0|\n",
      "|[file:/Users/sver...|cat.5343.jpg|  1.0|[file:/Users/sver...|[9.46370302699506...|       1.0|\n",
      "|[file:/Users/sver...|cat.5387.jpg|  1.0|[file:/Users/sver...|[1.11698466298548...|       2.0|\n",
      "|[file:/Users/sver...|cat.5516.jpg|  1.0|[file:/Users/sver...|[3.29864065861329...|       1.0|\n",
      "|[file:/Users/sver...|dog.5164.jpg|  2.0|[file:/Users/sver...|[1.25022279462427...|       2.0|\n",
      "|[file:/Users/sver...|dog.5218.jpg|  2.0|[file:/Users/sver...|[4.9651418976282E...|       2.0|\n",
      "|[file:/Users/sver...|dog.5229.jpg|  2.0|[file:/Users/sver...|[1.81052803327474...|       2.0|\n",
      "|[file:/Users/sver...|dog.5478.jpg|  2.0|[file:/Users/sver...|[7.68174686527345...|       2.0|\n",
      "|[file:/Users/sver...|  dog.59.jpg|  2.0|[file:/Users/sver...|[1.59479270223528...|       2.0|\n",
      "|[file:/Users/sver...|dog.5997.jpg|  2.0|[file:/Users/sver...|[1.52367761074856...|       2.0|\n",
      "|[file:/Users/sver...|   cat.5.jpg|  1.0|[file:/Users/sver...|[1.90239388757618...|       1.0|\n",
      "|[file:/Users/sver...|cat.5009.jpg|  1.0|[file:/Users/sver...|[1.74414399225497...|       1.0|\n",
      "|[file:/Users/sver...|cat.5074.jpg|  1.0|[file:/Users/sver...|[8.85745862433395...|       2.0|\n",
      "|[file:/Users/sver...|cat.5171.jpg|  1.0|[file:/Users/sver...|[2.09370133234187...|       2.0|\n",
      "|[file:/Users/sver...|cat.5182.jpg|  1.0|[file:/Users/sver...|[4.05893018751157...|       1.0|\n",
      "|[file:/Users/sver...|cat.5203.jpg|  1.0|[file:/Users/sver...|[3.36655659793905...|       1.0|\n",
      "|[file:/Users/sver...|cat.5214.jpg|  1.0|[file:/Users/sver...|[2.29024135478539...|       1.0|\n",
      "|[file:/Users/sver...|cat.5355.jpg|  1.0|[file:/Users/sver...|[2.09603854273154...|       2.0|\n",
      "+--------------------+------------+-----+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Test Error = 0.102941 \n"
     ]
    }
   ],
   "source": [
    "    sparkConf = SparkConf().setAppName(\"ImageTransferLearningExample\")\n",
    "    sc = get_nncontext(sparkConf)\n",
    "    #redire_spark_logs()\n",
    "\n",
    "    model_path = '/Users/svermoli/sandbox/dogsvscats/model/bigdl_inception-v1_imagenet_0.4.0.model' \n",
    "    image_path = '/Users/svermoli/sandbox/dogsvscats/demo' + '/*/*'\n",
    "    imageDF = NNImageReader.readImages(image_path, sc).repartition(12).cache()\n",
    "    \n",
    "    print(\"Partition number: \", imageDF.rdd.getNumPartitions())\n",
    "    print(\"Image number\", imageDF.count())\n",
    "\n",
    "    #change code for house style here:\n",
    "    \n",
    "    getName = udf(lambda row: re.search(r'(cat|dog)\\.([\\d]*)\\.jpg', row[0], re.IGNORECASE).group(0), StringType())\n",
    "    getLabel = udf(lambda name: 1.0 if name.startswith('cat') else 2.0, DoubleType())\n",
    "    labelDF = imageDF.withColumn(\"name\", getName(col(\"image\"))) \\\n",
    "        .withColumn(\"label\", getLabel(col('name')))\n",
    "    (trainingDF, validationDF) = labelDF.randomSplit([0.9, 0.1])\n",
    "\n",
    "    # compose a pipeline that includes feature transform, pretrained model and Logistic Regression\n",
    "    transformer = NNImageTransformer(\n",
    "        image.Pipeline([Resize(256, 256), CenterCrop(224, 224), ChannelNormalize(123.0, 117.0, 104.0)])\n",
    "    ).setInputCol(\"image\").setOutputCol(\"features\")\n",
    "\n",
    "    preTrainedNNModel = NNModel(Model.loadModel(model_path), [3,224,224]).setPredictionCol(\"embedding\")\n",
    "    \n",
    "    print(\"Loaded pretrained model\")\n",
    "    \n",
    "    lrModel = Sequential().add(Linear(1000, 2)).add(LogSoftMax())\n",
    "    classifier = NNClassifier(lrModel, ClassNLLCriterion(), [1000]) \\\n",
    "        .setLearningRate(0.003).setBatchSize(40).setMaxEpoch(20).setFeaturesCol(\"embedding\")\n",
    "\n",
    "    print (\"stage 1\")    \n",
    "    pipeline = Pipeline(stages=[transformer, preTrainedNNModel, classifier])\n",
    "    print (\"start training\")\n",
    "    catdogModel = pipeline.fit(trainingDF)\n",
    "    print (\"end training\")\n",
    "    predictionDF = catdogModel.transform(validationDF).cache()\n",
    "    predictionDF.show()\n",
    "\n",
    "    \n",
    "    evaluator = MulticlassClassificationEvaluator(\n",
    "        labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "    accuracy = evaluator.evaluate(predictionDF)\n",
    "    # expected error should be less than 10%\n",
    "    print(\"Test Error = %g \" % (1.0 - accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
