{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from bigdl.util.common import * \n",
    "from bigdl.transform.vision.image import *\n",
    "from bigdl.transform.vision import image\n",
    "from pyspark.sql.functions import col, udf\n",
    "from pyspark.sql.types import DoubleType, StringType\n",
    "from bigdl.nn.layer import *\n",
    "from bigdl.nn.criterion import *\n",
    "from pyspark import SparkConf\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "from zoo.common.nncontext import *\n",
    "from zoo.pipeline.nnframes.nn_classifier import *\n",
    "from zoo.pipeline.nnframes.nn_image_reader import *\n",
    "from zoo.pipeline.nnframes.nn_image_transformer import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating: createResize\n",
      "creating: createCenterCrop\n",
      "creating: createChannelNormalize\n",
      "creating: createPipeline\n",
      "creating: createNNImageTransformer\n",
      "creating: createNNModel\n",
      "creating: createSequential\n",
      "creating: createLinear\n",
      "creating: createLogSoftMax\n",
      "creating: createClassNLLCriterion\n",
      "creating: createNNClassifier\n",
      "+--------------------+------------+-----+--------------------+--------------------+----------+\n",
      "|               image|        name|label|            features|           embedding|prediction|\n",
      "+--------------------+------------+-----+--------------------+--------------------+----------+\n",
      "|[file:/Users/sver...|cat.5006.jpg|  1.0|[file:/Users/sver...|[3.01570817100582...|       1.0|\n",
      "|[file:/Users/sver...|cat.5008.jpg|  1.0|[file:/Users/sver...|[2.42088958657404...|       1.0|\n",
      "|[file:/Users/sver...|cat.5016.jpg|  1.0|[file:/Users/sver...|[3.27992069060201...|       1.0|\n",
      "|[file:/Users/sver...|cat.5017.jpg|  1.0|[file:/Users/sver...|[4.88881005367147...|       1.0|\n",
      "|[file:/Users/sver...| cat.502.jpg|  1.0|[file:/Users/sver...|[3.84301165468059...|       1.0|\n",
      "|[file:/Users/sver...|cat.5023.jpg|  1.0|[file:/Users/sver...|[4.65423090645344...|       1.0|\n",
      "|[file:/Users/sver...|cat.5030.jpg|  1.0|[file:/Users/sver...|[4.74546359328087...|       1.0|\n",
      "|[file:/Users/sver...|cat.5035.jpg|  1.0|[file:/Users/sver...|[0.00158695981372...|       2.0|\n",
      "|[file:/Users/sver...|cat.5039.jpg|  1.0|[file:/Users/sver...|[7.10753283783560...|       1.0|\n",
      "|[file:/Users/sver...|cat.5051.jpg|  1.0|[file:/Users/sver...|[3.02720627587405...|       1.0|\n",
      "|[file:/Users/sver...|cat.5055.jpg|  1.0|[file:/Users/sver...|[1.19357951916754...|       1.0|\n",
      "|[file:/Users/sver...|cat.5058.jpg|  1.0|[file:/Users/sver...|[3.11795315610652...|       1.0|\n",
      "|[file:/Users/sver...|cat.5062.jpg|  1.0|[file:/Users/sver...|[1.03216116258408...|       2.0|\n",
      "|[file:/Users/sver...|cat.5065.jpg|  1.0|[file:/Users/sver...|[4.56207590104895...|       1.0|\n",
      "|[file:/Users/sver...|cat.5106.jpg|  1.0|[file:/Users/sver...|[1.55249756517150...|       1.0|\n",
      "|[file:/Users/sver...|cat.5108.jpg|  1.0|[file:/Users/sver...|[3.88924860317274...|       1.0|\n",
      "|[file:/Users/sver...|cat.5120.jpg|  1.0|[file:/Users/sver...|[1.14797649075626...|       1.0|\n",
      "|[file:/Users/sver...|cat.5132.jpg|  1.0|[file:/Users/sver...|[1.96168093680171...|       1.0|\n",
      "|[file:/Users/sver...|cat.5139.jpg|  1.0|[file:/Users/sver...|[8.19997239887015...|       1.0|\n",
      "|[file:/Users/sver...|cat.5153.jpg|  1.0|[file:/Users/sver...|[4.36920163338072...|       2.0|\n",
      "+--------------------+------------+-----+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Test Error = 0.103896 \n"
     ]
    }
   ],
   "source": [
    "    sparkConf = SparkConf().setAppName(\"ImageTransferLearningExample\")\n",
    "    sc = get_nncontext(sparkConf)\n",
    "    redire_spark_logs()\n",
    "\n",
    "    model_path = '/Users/svermoli/sandbox/dogsvscats/model/bigdl_inception-v1_imagenet_0.4.0.model' \n",
    "    image_path = '/Users/svermoli/sandbox/dogsvscats/demo' + '/*/*'\n",
    "    imageDF = NNImageReader.readImages(image_path, sc)\n",
    "\n",
    "    #change code for house style here:\n",
    "    \n",
    "    getName = udf(lambda row: re.search(r'(cat|dog)\\.([\\d]*)\\.jpg', row[0], re.IGNORECASE).group(0), StringType())\n",
    "    getLabel = udf(lambda name: 1.0 if name.startswith('cat') else 2.0, DoubleType())\n",
    "    labelDF = imageDF.withColumn(\"name\", getName(col(\"image\"))) \\\n",
    "        .withColumn(\"label\", getLabel(col('name')))\n",
    "    (trainingDF, validationDF) = labelDF.randomSplit([0.9, 0.1])\n",
    "\n",
    "    # compose a pipeline that includes feature transform, pretrained model and Logistic Regression\n",
    "    transformer = NNImageTransformer(\n",
    "        image.Pipeline([Resize(256, 256), CenterCrop(224, 224), ChannelNormalize(123.0, 117.0, 104.0)])\n",
    "    ).setInputCol(\"image\").setOutputCol(\"features\")\n",
    "\n",
    "    preTrainedNNModel = NNModel(Model.loadModel(model_path), [3,224,224]).setPredictionCol(\"embedding\")\n",
    "\n",
    "    lrModel = Sequential().add(Linear(1000, 2)).add(LogSoftMax())\n",
    "    classifier = NNClassifier(lrModel, ClassNLLCriterion(), [1000]) \\\n",
    "        .setLearningRate(0.003).setBatchSize(40).setMaxEpoch(20).setFeaturesCol(\"embedding\")\n",
    "\n",
    "    pipeline = Pipeline(stages=[transformer, preTrainedNNModel, classifier])\n",
    "\n",
    "    catdogModel = pipeline.fit(trainingDF)\n",
    "    predictionDF = catdogModel.transform(validationDF).cache()\n",
    "    predictionDF.show()\n",
    "\n",
    "    evaluator = MulticlassClassificationEvaluator(\n",
    "        labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "    accuracy = evaluator.evaluate(predictionDF)\n",
    "    # expected error should be less than 10%\n",
    "    print(\"Test Error = %g \" % (1.0 - accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
